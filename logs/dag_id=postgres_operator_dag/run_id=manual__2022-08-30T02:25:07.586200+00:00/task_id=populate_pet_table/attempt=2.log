[2022-08-30T02:26:35.516+0000] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: postgres_operator_dag.populate_pet_table manual__2022-08-30T02:25:07.586200+00:00 [queued]>
[2022-08-30T02:26:35.530+0000] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: postgres_operator_dag.populate_pet_table manual__2022-08-30T02:25:07.586200+00:00 [queued]>
[2022-08-30T02:26:35.530+0000] {taskinstance.py:1368} INFO - 
--------------------------------------------------------------------------------
[2022-08-30T02:26:35.530+0000] {taskinstance.py:1369} INFO - Starting attempt 2 of 2
[2022-08-30T02:26:35.530+0000] {taskinstance.py:1370} INFO - 
--------------------------------------------------------------------------------
[2022-08-30T02:26:35.554+0000] {taskinstance.py:1389} INFO - Executing <Task(PostgresOperator): populate_pet_table> on 2022-08-30 02:25:07.586200+00:00
[2022-08-30T02:26:35.562+0000] {standard_task_runner.py:52} INFO - Started process 189 to run task
[2022-08-30T02:26:35.568+0000] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'postgres_operator_dag', 'populate_pet_table', 'manual__2022-08-30T02:25:07.586200+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/postgres_operator_dag.py', '--cfg-path', '/tmp/tmpu6309t7r', '--error-file', '/tmp/tmp5ucnn8jb']
[2022-08-30T02:26:35.568+0000] {standard_task_runner.py:80} INFO - Job 24: Subtask populate_pet_table
[2022-08-30T02:26:35.638+0000] {task_command.py:371} INFO - Running <TaskInstance: postgres_operator_dag.populate_pet_table manual__2022-08-30T02:25:07.586200+00:00 [running]> on host 7f44611b6b02
[2022-08-30T02:26:35.749+0000] {taskinstance.py:1583} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=postgres_operator_dag
AIRFLOW_CTX_TASK_ID=populate_pet_table
AIRFLOW_CTX_EXECUTION_DATE=2022-08-30T02:25:07.586200+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-08-30T02:25:07.586200+00:00
[2022-08-30T02:26:35.766+0000] {base.py:68} INFO - Using connection ID 'postgres_default' for task execution.
[2022-08-30T02:26:35.771+0000] {sql.py:315} INFO - Running statement: INSERT INTO pet (name, pet_type, birth_date, OWNER)
            VALUES ( 'Max', 'Dog', '2018-07-05', 'Jane');
            INSERT INTO pet (name, pet_type, birth_date, OWNER)
            VALUES ( 'Susie', 'Cat', '2019-05-01', 'Phil');
            INSERT INTO pet (name, pet_type, birth_date, OWNER)
            VALUES ( 'Lester', 'Hamster', '2020-06-23', 'Lily');
            INSERT INTO pet (name, pet_type, birth_date, OWNER)
            VALUES ( 'Quincy', 'Parrot', '2013-08-11', 'Anne'), parameters: None
[2022-08-30T02:26:35.772+0000] {sql.py:324} INFO - Rows affected: 1
[2022-08-30T02:26:35.786+0000] {taskinstance.py:1412} INFO - Marking task as SUCCESS. dag_id=postgres_operator_dag, task_id=populate_pet_table, execution_date=20220830T022507, start_date=20220830T022635, end_date=20220830T022635
[2022-08-30T02:26:35.819+0000] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-30T02:26:35.859+0000] {local_task_job.py:279} INFO - 0 downstream tasks scheduled from follow-on schedule check
